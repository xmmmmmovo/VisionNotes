{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 0 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"test2.jpg\")\n",
    "\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(\"short_hamilton_clip.mp4\")\n",
    "\n",
    "frames = []\n",
    "frame_count = 0\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Bail out when the video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Save each frame of the video to a list\n",
    "    frame_count += 1\n",
    "    frames.append(frame)\n",
    "\n",
    "    # Every 128 frames (the default batch size), batch process the list of frames to find faces\n",
    "    if len(frames) == 128:\n",
    "        batch_of_face_locations = face_recognition.batch_face_locations(frames, number_of_times_to_upsample=0)\n",
    "\n",
    "        # Now let's list all the faces we found in all 128 frames\n",
    "        for frame_number_in_batch, face_locations in enumerate(batch_of_face_locations):\n",
    "            number_of_faces_in_frame = len(face_locations)\n",
    "\n",
    "            frame_number = frame_count - 128 + frame_number_in_batch\n",
    "            print(\"I found {} face(s) in frame #{}.\".format(number_of_faces_in_frame, frame_number))\n",
    "\n",
    "            for face_location in face_locations:\n",
    "                # Print the location of each face in this frame\n",
    "                top, right, bottom, left = face_location\n",
    "                print(\" - A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "        # Clear the frames array to start the next batch\n",
    "        frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
